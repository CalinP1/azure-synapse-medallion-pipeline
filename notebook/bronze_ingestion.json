{
	"name": "bronze_ingestion",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "sparkpool",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 1,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "1",
				"spark.dynamicAllocation.maxExecutors": "1",
				"spark.autotune.trackingId": "d215dc63-074b-44ce-942d-29eb377fe0b7"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/32ed6f2a-a561-477a-8242-a37e60600b34/resourceGroups/synapseWork/providers/Microsoft.Synapse/workspaces/synapseforwork/bigDataPools/sparkpool",
				"name": "sparkpool",
				"type": "Spark",
				"endpoint": "https://synapseforwork.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.5",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**Importing the libraries needed. Pyspark to work with data, requests for retrieveing data from kaggle, zipfile to unzip the retrieved data, io to transform the binary data to a file-like object.**"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql import SparkSession\n",
					"import requests\n",
					"import zipfile\n",
					"import io\n",
					"from datetime import datetime\n",
					"print(\"Libs imported succesfully\")\n",
					"print(f\"Check the time - {datetime.now()}\")"
				],
				"execution_count": 10
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"We import Microsoft spark utilities to retrieve the secret name and key from vault for the Kaggle api fetch (this method is specific only for Azure Synapse)"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"from notebookutils import mssparkutils"
				],
				"execution_count": 11
			},
			{
				"cell_type": "code",
				"source": [
					"vault_url = \"https://kaggle-key-api.vault.azure.net/\"\n",
					"vault_name = \"kaggle-name\"\n",
					"vault_key = 'kaggle-key'"
				],
				"execution_count": 13
			},
			{
				"cell_type": "code",
				"source": [
					"vault_kaggle_name = mssparkutils.credentials.getSecret(vault_url, vault_name)\n",
					"vault_kaggle_key = mssparkutils.credentials.getSecret(vault_url, vault_key)"
				],
				"execution_count": 18
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"We check to see if we did the right credentials retrieval"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"print(f\"Username type: {type(vault_kaggle_name)}\")\n",
					"print(f\"Username length: {len(vault_kaggle_name)} characters\")"
				],
				"execution_count": 19
			}
		]
	}
}